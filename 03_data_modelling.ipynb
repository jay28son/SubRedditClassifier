{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the data collected from the data collection notebook\n",
    "df_wsb = pd.read_csv('./csv_files/wsb_data.csv')\n",
    "df_wsb_test = pd.read_csv('./csv_files/wsb_data_test.csv')\n",
    "df_sm = pd.read_csv('./csv_files/sm_data.csv')\n",
    "df_sm_test = pd.read_csv('./csv_files/sm_data_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine the datasets into one dataframe for test and train\n",
    "df = pd.concat([df_wsb,df_sm], axis = 0)\n",
    "df_test = pd.concat([df_wsb_test,df_sm_test],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unnamed index column\n",
    "df.drop(columns='Unnamed: 0',inplace= True)\n",
    "df_test.drop(columns='Unnamed: 0',inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit         0\n",
       "selftext       4671\n",
       "title             0\n",
       "created_utc       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the train dataset for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit        0\n",
       "selftext       114\n",
       "title            0\n",
       "created_utc      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the test dataset for null values\n",
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace the null values in the selftext column with a blank space, theres no way for us to get that data and we dont want to drop it all\n",
    "df.fillna('',inplace = True)\n",
    "df_test.fillna('',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wallstreetbets    4000\n",
       "StockMarket       4000\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binarize the subreddit classes\n",
    "df['subreddit'] = df['subreddit'].map({'wallstreetbets': 1, 'StockMarket': 0 })\n",
    "df_test['subreddit'] = df_test['subreddit'].map({'wallstreetbets': 1, 'StockMarket': 0 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4000\n",
       "0    4000\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checked if the binarize worked\n",
    "df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create X and y \n",
    "X= df['title']\n",
    "y = df['subreddit']\n",
    "test_X= df_test['title']\n",
    "test_y = df_test['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Models being used from sklearn and xgboost\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split our X and Y\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,stratify=y,random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling \n",
    "For our modelling we're going to be trying five different types of models, XGboost, Logistic Regression, Bagging, Random Forest And KNN. We chose to do five models because so we can have a better chance of getting a higher classification accuracy, and it also helps see what the average of the accuracy would be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xgboost Model, default parameters\n",
    "\n",
    "For our first model we're going to be using the default parameters within the xgboost to get a baseline of the score using xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform the text with countvectorizer and then put that into an xgb classifier\n",
    "pipe_xgb = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('xgb', xgb.XGBClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                ('xgb',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, early_stopping_rounds=None,\n",
       "                               enable_categorical=False, eval_metric=None,\n",
       "                               feature_types=None, gamma=0, gpu_id=-1,\n",
       "                               grow_policy='depthwise', importance_type=None,\n",
       "                               interaction_constraints='',\n",
       "                               learning_rate=0.300000012, max_bin=256,\n",
       "                               max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "                               max_delta_step=0, max_depth=6, max_leaves=0,\n",
       "                               min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=100,\n",
       "                               n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
       "                               random_state=0, ...))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit Xgb model\n",
    "pipe_xgb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8261666666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.736"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model scores\n",
    "print(pipe_xgb.score(X_train,y_train))\n",
    "pipe_xgb.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just looking at the scores we can see that our model is overfit using the default parameters but it predicts the right subreddit 73% of the time, 23% higher than the baseline. This is pretty decent of an increase but lets see if we can either get a less overfit model or higher test accuracy utilizing gridsearch with xgb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XgBoost Model with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Refit the Xgboost model with more optimized hyperparameters\n",
    "pipe_xgb = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('xgb', xgb.XGBClassifier())\n",
    "])\n",
    "pipe_params = {\n",
    "    'xgb__learning_rate':[0.3,1.0],\n",
    "    'xgb__max_depth':[3,7],\n",
    "    'xgb__base_score':[0.3,0.7],\n",
    "    'cvec__max_features': [2000,8000],\n",
    "    'cvec__stop_words':[None,'english'],\n",
    "    'cvec__ngram_range':[(1,1),(2,2),(3,3)],\n",
    "    'cvec__min_df':[1,2],\n",
    "    'cvec__max_df':[0.5,0.9]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearch\n",
    "gs_xgb = GridSearchCV(\n",
    "    pipe_xgb,\n",
    "    param_grid = pipe_params,\n",
    "    cv = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('xgb',\n",
       "                                        XGBClassifier(base_score=None,\n",
       "                                                      booster=None,\n",
       "                                                      callbacks=None,\n",
       "                                                      colsample_bylevel=None,\n",
       "                                                      colsample_bynode=None,\n",
       "                                                      colsample_bytree=None,\n",
       "                                                      early_stopping_rounds=None,\n",
       "                                                      enable_categorical=False,\n",
       "                                                      eval_metric=None,\n",
       "                                                      feature_types=None,\n",
       "                                                      gamma=None, gpu_id=None,\n",
       "                                                      grow_policy=None,\n",
       "                                                      importance_type=Non...\n",
       "                                                      monotone_constraints=None,\n",
       "                                                      n_estimators=100,\n",
       "                                                      n_jobs=None,\n",
       "                                                      num_parallel_tree=None,\n",
       "                                                      predictor=None,\n",
       "                                                      random_state=None, ...))]),\n",
       "             param_grid={'cvec__max_df': [0.5, 0.9],\n",
       "                         'cvec__max_features': [2000, 8000],\n",
       "                         'cvec__min_df': [1, 2],\n",
       "                         'cvec__ngram_range': [(1, 1), (2, 2), (3, 3)],\n",
       "                         'cvec__stop_words': [None, 'english'],\n",
       "                         'xgb__base_score': [0.3, 0.7],\n",
       "                         'xgb__learning_rate': [0.3, 1.0],\n",
       "                         'xgb__max_depth': [3, 7]})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit 2nd xgb model\n",
    "gs_xgb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.5,\n",
       " 'cvec__max_features': 2000,\n",
       " 'cvec__min_df': 1,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': None,\n",
       " 'xgb__base_score': 0.3,\n",
       " 'xgb__learning_rate': 0.3,\n",
       " 'xgb__max_depth': 7}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checkout what the best paramters were during the grid search\n",
    "gs_xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.74"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Look at the scores to check for overfitting and test score\n",
    "print(gs_xgb.score(X_train,y_train))\n",
    "gs_xgb.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score with the given parameters was only 0.04% better than the default parameters and it also got more overfit, but utilizing\n",
    "best_params I can see how to adjust the parameters more to be fit better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remake the parameters to be even more optimized\n",
    "pipe_xgb_2 = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('xgb', xgb.XGBClassifier())\n",
    "])\n",
    "pipe_params_2 = {\n",
    "    'xgb__learning_rate':[0.1,0.3,0.5],\n",
    "    'xgb__max_depth':[7],\n",
    "    'xgb__base_score':[0.1,0.3,0.5],\n",
    "    'xgb__n_estimators':[50,100],\n",
    "    'xgb__min_child_weight':[1,2],\n",
    "    'xgb__colsample_bytree':[0.3,0.6],\n",
    "    'cvec__stop_words':[None,'english'],\n",
    "    'cvec__ngram_range':[(1,1),(2,2),(3,3)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_xgb_2 = GridSearchCV(\n",
    "    pipe_xgb_2,\n",
    "    param_grid=pipe_params_2,\n",
    "    cv = 3\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('xgb',\n",
       "                                        XGBClassifier(base_score=None,\n",
       "                                                      booster=None,\n",
       "                                                      callbacks=None,\n",
       "                                                      colsample_bylevel=None,\n",
       "                                                      colsample_bynode=None,\n",
       "                                                      colsample_bytree=None,\n",
       "                                                      early_stopping_rounds=None,\n",
       "                                                      enable_categorical=False,\n",
       "                                                      eval_metric=None,\n",
       "                                                      feature_types=None,\n",
       "                                                      gamma=None, gpu_id=None,\n",
       "                                                      grow_policy=None,\n",
       "                                                      importance_type=Non...\n",
       "                                                      n_estimators=100,\n",
       "                                                      n_jobs=None,\n",
       "                                                      num_parallel_tree=None,\n",
       "                                                      predictor=None,\n",
       "                                                      random_state=None, ...))]),\n",
       "             param_grid={'cvec__ngram_range': [(1, 1), (2, 2), (3, 3)],\n",
       "                         'cvec__stop_words': [None, 'english'],\n",
       "                         'xgb__base_score': [0.1, 0.3, 0.5],\n",
       "                         'xgb__colsample_bytree': [0.3, 0.6],\n",
       "                         'xgb__learning_rate': [0.1, 0.3, 0.5],\n",
       "                         'xgb__max_depth': [7], 'xgb__min_child_weight': [1, 2],\n",
       "                         'xgb__n_estimators': [50, 100]})"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_xgb_2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': None,\n",
       " 'xgb__base_score': 0.5,\n",
       " 'xgb__colsample_bytree': 0.6,\n",
       " 'xgb__learning_rate': 0.5,\n",
       " 'xgb__max_depth': 7,\n",
       " 'xgb__min_child_weight': 1,\n",
       " 'xgb__n_estimators': 100}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the best parameters for 2nd xgb model\n",
    "gs_xgb_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8491666666666666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.741"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gs_xgb_2.score(X_train,y_train))\n",
    "gs_xgb_2.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By fine tuning the hyperparameters we were only able to get a 0.001 increase from the previous optimization. This 0.001% increase would not be worth considering the increased runtime that it added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import RandomForest ensemble library and randint to be used for randomizedsearch\n",
    "from scipy.stats import randint\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make an estimated base of what we want our parameters to look like.\n",
    "pipe_rf = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "pipe_rf_params = {\n",
    "    'cvec__max_features':randint(1000,10000),\n",
    "    'cvec__stop_words':[None,'english'],\n",
    "    'cvec__ngram_range':[(1,1),(2,2),(3,3)],\n",
    "    'cvec__min_df':randint(1,4),\n",
    "    'cvec__max_df':[0.5,0.7,0.9],\n",
    "    'rf__n_estimators':list(np.arange(10,500, step = 50)),\n",
    "    'rf__max_depth':list(np.arange(1,100,step = 10)),\n",
    "    'rf__min_samples_split':np.arange(2,10,step = 2),\n",
    "    'rf__min_samples_leaf':randint(1,10)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomizedSearch makes it so it can cover a wider array of numbers compared to gridsearch and it can fit with a less amount of time.\n",
    "rs_rf = RandomizedSearchCV(\n",
    "    pipe_rf,\n",
    "    param_distributions= pipe_rf_params,\n",
    "    cv=3\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                             ('rf', RandomForestClassifier())]),\n",
       "                   param_distributions={'cvec__max_df': [0.5, 0.7, 0.9],\n",
       "                                        'cvec__max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fc03811b520>,\n",
       "                                        'cvec__min_df': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fc03811b1c0>,\n",
       "                                        'cvec__ngram_range': [(1, 1), (2, 2),\n",
       "                                                              (3, 3)],\n",
       "                                        'cvec__stop_words': [None, 'english'],\n",
       "                                        'rf__max_depth': [1, 11, 21, 31, 41, 51,\n",
       "                                                          61, 71, 81, 91],\n",
       "                                        'rf__min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fc06d006640>,\n",
       "                                        'rf__min_samples_split': array([2, 4, 6, 8]),\n",
       "                                        'rf__n_estimators': [10, 60, 110, 160,\n",
       "                                                             210, 260, 310, 360,\n",
       "                                                             410, 460]})"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7813333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7315"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(rs_rf.score(X_train,y_train))\n",
    "rs_rf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The randomized Forest model performed worse compared to the xgboost model but it did end up being less overfit comparitively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearched Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Bagging library from sklearn\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create pipeline and make the parameters for a basic gridsearched bagging model\n",
    "pipe_bag = Pipeline([\n",
    "    ('cvec',CountVectorizer()),\n",
    "    ('bag', BaggingClassifier())\n",
    "])\n",
    "pipe_bag_params = {\n",
    "    'cvec__stop_words':[None],\n",
    "    'cvec__ngram_range':[(1,1),(2,2)],\n",
    "    'bag__n_estimators':[100,150],\n",
    "    'bag__max_samples':[0.7,0.9],\n",
    "    'bag__max_features':[500,1000]  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_bag = GridSearchCV(\n",
    "    pipe_bag,\n",
    "    pipe_bag_params,\n",
    "    cv=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('bag', BaggingClassifier())]),\n",
       "             param_grid={'bag__max_features': [500, 1000],\n",
       "                         'bag__max_samples': [0.7, 0.9],\n",
       "                         'bag__n_estimators': [100, 150],\n",
       "                         'cvec__ngram_range': [(1, 1), (2, 2)],\n",
       "                         'cvec__stop_words': [None]})"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_bag.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bag__max_features': 1000,\n",
       " 'bag__max_samples': 0.7,\n",
       " 'bag__n_estimators': 150,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': None}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best Parameters\n",
    "gs_bag.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9338333333333333\n",
      "0.7595\n"
     ]
    }
   ],
   "source": [
    "print(gs_bag.score(X_train,y_train))\n",
    "print(gs_bag.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far this gridsearched bagging model was our best model getting an accuracy of almost 76% but it was severely overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomSearched Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our bagging model was our best model so far I wanted to try and implement randomsearch to see if i can make a bagging model with better optimized parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rs_bag = Pipeline([\n",
    "    ('cvec',CountVectorizer()),\n",
    "    ('bag',BaggingClassifier())\n",
    "])\n",
    "pipe_rs_bag_params = {\n",
    "    'cvec__ngram_range':[(1,1),(3,3)],\n",
    "    'cvec__min_df':randint(1,10),\n",
    "    'cvec__max_df':[0.5,0.7,0.9],\n",
    "    'bag__n_estimators':list(np.arange(5000,6000, step = 100)),\n",
    "    'bag__max_samples':[0.7,0.9],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_bag = RandomizedSearchCV(\n",
    "    pipe_rs_bag,\n",
    "    param_distributions = pipe_rs_bag_params,\n",
    "    cv = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_bag.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bag__max_features': 400,\n",
       " 'bag__max_samples': 0.9,\n",
       " 'bag__n_estimators': 5500,\n",
       " 'cvec__max_df': 0.5,\n",
       " 'cvec__min_df': 1,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': None}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_bag.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9146666666666666\n",
      "0.767\n"
     ]
    }
   ],
   "source": [
    "print(rs_bag.score(X_train,y_train))\n",
    "print(rs_bag.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By utilizing randomsearch we were able to get a 0.008% difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make KNN pipeline and put in some random parameters to be gridsearched\n",
    "pipe_knn = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('knn',KNeighborsClassifier())\n",
    "])\n",
    "pipe_knn_params = {\n",
    "    'cvec__stop_words':[None],\n",
    "    'cvec__ngram_range':[(1,1),(3,3)],\n",
    "    'cvec__min_df':[1,2,3],\n",
    "    'cvec__max_df':[0.5,0.7,0.9],\n",
    "    'knn__n_neighbors': [1,3,5],\n",
    "    'knn__p':[2,3,4],\n",
    "    'knn__weights':['uniform','distance',None]\n",
    "}\n",
    "gs_knn = GridSearchCV(\n",
    "    pipe_knn,\n",
    "    param_grid = pipe_knn_params,\n",
    "    cv = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaysonv/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "972 fits failed out of a total of 1458.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "972 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jaysonv/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jaysonv/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/jaysonv/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/neighbors/_classification.py\", line 198, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"/Users/jaysonv/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/neighbors/_base.py\", line 508, in _fit\n",
      "    raise ValueError(\n",
      "ValueError: Metric 'minkowski' not valid for sparse input. Use sorted(sklearn.neighbors.VALID_METRICS_SPARSE['brute']) to get valid options. Metric can also be a callable function.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/jaysonv/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.64616667 0.64616667 0.64616667        nan        nan        nan\n",
      "        nan        nan        nan 0.61516667 0.62816667 0.61516667\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.60816667 0.621      0.60816667        nan        nan        nan\n",
      "        nan        nan        nan 0.55583333 0.55583333 0.55583333\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.52966667 0.5505     0.52966667        nan        nan        nan\n",
      "        nan        nan        nan 0.51383333 0.53216667 0.51383333\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.66666667 0.66666667 0.66666667        nan        nan        nan\n",
      "        nan        nan        nan 0.6395     0.65133333 0.6395\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.62733333 0.64366667 0.62733333        nan        nan        nan\n",
      "        nan        nan        nan 0.53383333 0.53383333 0.53383333\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.53       0.534      0.53              nan        nan        nan\n",
      "        nan        nan        nan 0.55383333 0.55816667 0.55383333\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.65583333 0.65583333 0.65583333        nan        nan        nan\n",
      "        nan        nan        nan 0.65366667 0.66333333 0.65366667\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.638      0.652      0.638             nan        nan        nan\n",
      "        nan        nan        nan 0.52366667 0.52366667 0.52366667\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.52216667 0.52466667 0.52216667        nan        nan        nan\n",
      "        nan        nan        nan 0.54966667 0.551      0.54966667\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.64616667 0.64616667 0.64616667        nan        nan        nan\n",
      "        nan        nan        nan 0.61516667 0.62816667 0.61516667\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.60816667 0.621      0.60816667        nan        nan        nan\n",
      "        nan        nan        nan 0.55583333 0.55583333 0.55583333\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.52966667 0.5505     0.52966667        nan        nan        nan\n",
      "        nan        nan        nan 0.51383333 0.53216667 0.51383333\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.66666667 0.66666667 0.66666667        nan        nan        nan\n",
      "        nan        nan        nan 0.6395     0.65133333 0.6395\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.62733333 0.64366667 0.62733333        nan        nan        nan\n",
      "        nan        nan        nan 0.53383333 0.53383333 0.53383333\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.53       0.534      0.53              nan        nan        nan\n",
      "        nan        nan        nan 0.55383333 0.55816667 0.55383333\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.65583333 0.65583333 0.65583333        nan        nan        nan\n",
      "        nan        nan        nan 0.65366667 0.66333333 0.65366667\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.638      0.652      0.638             nan        nan        nan\n",
      "        nan        nan        nan 0.52366667 0.52366667 0.52366667\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.52216667 0.52466667 0.52216667        nan        nan        nan\n",
      "        nan        nan        nan 0.54966667 0.551      0.54966667\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.64616667 0.64616667 0.64616667        nan        nan        nan\n",
      "        nan        nan        nan 0.61516667 0.62816667 0.61516667\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.60816667 0.621      0.60816667        nan        nan        nan\n",
      "        nan        nan        nan 0.55583333 0.55583333 0.55583333\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.52966667 0.5505     0.52966667        nan        nan        nan\n",
      "        nan        nan        nan 0.51383333 0.53216667 0.51383333\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.66666667 0.66666667 0.66666667        nan        nan        nan\n",
      "        nan        nan        nan 0.6395     0.65133333 0.6395\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.62733333 0.64366667 0.62733333        nan        nan        nan\n",
      "        nan        nan        nan 0.53383333 0.53383333 0.53383333\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.53       0.534      0.53              nan        nan        nan\n",
      "        nan        nan        nan 0.55383333 0.55816667 0.55383333\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.65583333 0.65583333 0.65583333        nan        nan        nan\n",
      "        nan        nan        nan 0.65366667 0.66333333 0.65366667\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.638      0.652      0.638             nan        nan        nan\n",
      "        nan        nan        nan 0.52366667 0.52366667 0.52366667\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.52216667 0.52466667 0.52216667        nan        nan        nan\n",
      "        nan        nan        nan 0.54966667 0.551      0.54966667\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('knn', KNeighborsClassifier())]),\n",
       "             param_grid={'cvec__max_df': [0.5, 0.7, 0.9],\n",
       "                         'cvec__min_df': [1, 2, 3],\n",
       "                         'cvec__ngram_range': [(1, 1), (3, 3)],\n",
       "                         'cvec__stop_words': [None],\n",
       "                         'knn__n_neighbors': [1, 3, 5], 'knn__p': [2, 3, 4],\n",
       "                         'knn__weights': ['uniform', 'distance', None]})"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.5,\n",
       " 'cvec__max_features': 500,\n",
       " 'cvec__min_df': 3,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': None,\n",
       " 'knn__n_neighbors': 3,\n",
       " 'knn__p': 2,\n",
       " 'knn__weights': 'distance'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Knns Best Parameters\n",
    "gs_knn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.938\n",
      "0.667\n"
     ]
    }
   ],
   "source": [
    "#Check the scores for KNN Model\n",
    "print(gs_knn.score(X_train,y_train))\n",
    "print(gs_knn.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN was our worse model and conceptually this makes sense as the way it uses the distance of points to find out other points classifications and we are using pure texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "pipe_lr_params= {\n",
    "    'cvec__stop_words':[None,],\n",
    "    'cvec__ngram_range':[(1,1),(2,2),(3,3)],\n",
    "    'cvec__min_df':randint(1,4),\n",
    "    'cvec__max_df':[0.5,0.7,0.9],\n",
    "    'lr__penalty':['l2','l1','elasticnet'],\n",
    "    'lr__C':[0.3,0.5,0.7,0.9],\n",
    "    'lr__max_iter':randint(100,1000)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_lr = RandomizedSearchCV(\n",
    "    pipe_lr,\n",
    "    param_distributions = pipe_lr_params,\n",
    "    cv = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaysonv/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "21 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jaysonv/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jaysonv/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/jaysonv/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/jaysonv/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jaysonv/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/jaysonv/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/jaysonv/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/jaysonv/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/jaysonv/opt/anaconda3/envs/dsi/lib/python3.8/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.58216667        nan 0.66833333        nan        nan        nan\n",
      "        nan        nan 0.75433333        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                             ('lr', LogisticRegression())]),\n",
       "                   param_distributions={'cvec__max_df': [0.5, 0.7, 0.9],\n",
       "                                        'cvec__min_df': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fbfb9b7e310>,\n",
       "                                        'cvec__ngram_range': [(1, 1), (2, 2),\n",
       "                                                              (3, 3)],\n",
       "                                        'cvec__stop_words': [None],\n",
       "                                        'lr__C': [0.3, 0.5, 0.7, 0.9],\n",
       "                                        'lr__max_iter': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fbfb9b7e4f0>,\n",
       "                                        'lr__penalty': ['l2', 'l1',\n",
       "                                                        'elasticnet']})"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.7,\n",
       " 'cvec__max_features': 8264,\n",
       " 'cvec__min_df': 1,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': None,\n",
       " 'lr__C': 0.7,\n",
       " 'lr__max_iter': 440,\n",
       " 'lr__penalty': 'l2'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.762"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(rs_lr.score(X_train,y_train))\n",
    "rs_lr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying model to \"original\" data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For purpose of our problem statement we will run the bagging models on our \"original\" data and see which model performs the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make X and y on our original data\n",
    "test_X = df_test['title']\n",
    "test_y = df_test['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearched XgBoost: 0.685\n",
      "RandomSearched Logisitic Regression: 0.705\n",
      "GridSearched Bagging: 0.72\n",
      "RandomSearched Bagging: 0.765\n",
      "GridSearched KNN: 0.66\n",
      "Random Forest: 0.695\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'GridSearched XgBoost: {gs_xgb_2.score(test_X,test_y)}')\n",
    "print(f'RandomSearched Logisitic Regression: {rs_lr.score(test_X,test_y)}')\n",
    "print(f'GridSearched Bagging: {round(gs_bag.score(test_X,test_y),2)}')\n",
    "print(f'RandomSearched Bagging: {rs_bag.score(test_X,test_y)}')\n",
    "print(f'GridSearched KNN: {round(gs_knn.score(test_X,test_y),2)}')\n",
    "print(f'Random Forest: {rs_rf.score(test_X,test_y)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomSearched Bagging: 0.765\n"
     ]
    }
   ],
   "source": [
    "print(f'RandomSearched Bagging: {rs_bag.score(test_X,test_y)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the model that performed the best and generalized to new data the best was our RandomSearched bagging model. We will move forward and look closer into this model and see how it evaluated everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Model evaluation Libraries\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our preds to compared to the actual values\n",
    "preds = rs_bag.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm= confusion_matrix(test_y,preds,labels= rs_bag.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm,display_labels = ['WallStreetBets','StockMarket'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Actual Vs Predicted')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./images/ConfusionMatrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.67      0.74       100\n",
      "           1       0.72      0.86      0.79       100\n",
      "\n",
      "    accuracy                           0.77       200\n",
      "   macro avg       0.77      0.77      0.76       200\n",
      "weighted avg       0.77      0.77      0.76       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y,preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the confusion Matrix and classification report we can see that our model is having a harder time correctly classifying WallstreetBets. This could make a lot of sense because as shown earlier the text within WallstreetBets excluding a couple of phrases are pretty generic and was pretty common when looking at it with StockMarket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "abd0db753b5aa849fcd3ff8bd130488ba3623be7a2758c7f531c9ac28620d6eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
